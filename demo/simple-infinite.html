
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width">
  <title>SimVPv2 - ONNX Runtime Web</title>
  <script src="./enable-threads.js"></script>
</head>
<body>
  
  <p>Blue = input frames, green = output/predicted frames. See browser console for more data.</p>
  <select id="modelSelectEl">
    <option value="fortnite/fortnite_epoch13_1.7mil-steps_quantized.onnx;fortnite/input_output_data.json.br">fortnite - 1.7mil steps</option>
    <option value="fortnite/fortnite_epoch8_1mil-steps_quantized.onnx;fortnite/input_output_data.json.br">fortnite - 1mil steps</option>
    <option value="pokemon_gold/pokemon_gold_epoch15_1.5mil-steps_quantized.onnx;pokemon_gold/input_output_data.json.br">pokemon gold - 1.5mil steps</option>
    <option value="pokemon_gold/pokemon_gold_epoch10_1mil-steps_quantized.onnx;pokemon_gold/input_output_data.json.br">pokemon gold - 1mil steps</option>
    <option value="riseofgru/riseofgru_7238x5_steps_quantized.onnx;riseofgru/input_output_data.json.br">rise of gru - 36k steps</option>
  </select>
  <div style="display:flex; margin:0.5rem 0;"><input id="randomNoiseEl" type="checkbox"> use random noise as initial input</div>
  <button onclick="start(); this.disabled=true;">start</button>
  
  <p><a href="https://github.com/josephrocca/SimVP-web">github repo</a> - <a href="https://huggingface.co/rocca/simvp-web">huggingface repo</a></p>
  
  <div id="frameCtn"></div>
  
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.13.1/dist/ort.js"></script>
  <script>
    if(self.crossOriginIsolated) { // needs to be cross-origin-isolated to use wasm threads. you need to serve this html file with these two headers: https://web.dev/coop-coep/
      ort.env.wasm.numThreads = navigator.hardwareConcurrency / 2;
    }
    ort.env.wasm.proxy = true; // <-- run in a worker, not on main thread
    
    async function start() {
      
      console.log("Initializing...");
      let model = await ort.InferenceSession.create(`https://huggingface.co/rocca/simvp-web/resolve/main/onnx/${modelSelectEl.value.split(";")[0]}`, { executionProviders: ["wasm"] });
      
      let exampleDataBrotli = await fetch(`https://huggingface.co/rocca/simvp-web/resolve/main/onnx/${modelSelectEl.value.split(";")[1]}`).then(r => r.arrayBuffer());
      
      let brotli = await import("https://unpkg.com/brotli-wasm@1.3.1/index.web.js").then(m => m.default);
      let decompressedData = brotli.decompress(new Uint8Array(exampleDataBrotli));
      let exampleData = JSON.parse(new TextDecoder().decode(decompressedData));
      
      // `exampleData` contains a batch of 16 frame sequences for `input`, `ground_truth`, and `pytorch_prediction`, where each sample is 10 frames long.
      const batchI = Math.floor(Math.random()*exampleData.input.length);
      let inputData = exampleData.input[batchI].flat().flat().flat().flat().flat().flat();
      console.log("Input data:", inputData);
      
      let inputFrames = [];
      let frameSize = 64; // assumes square
      
      // Use random noise as initial input:
      if(randomNoiseEl.checked) {
        inputData = new Array(1*10*3*64*64).fill(0).map(_ => Math.random());
      }
      
      /*for(let i = 0; i < 10; i++) {
        let s = frameSize*frameSize;
        let r = inputData.slice(3*i*s + s*0, 3*i*s + s*1);
        let g = inputData.slice(3*i*s + s*1, 3*i*s + s*2);
        let b = inputData.slice(3*i*s + s*2, 3*i*s + s*3);
        inputFrames.push({r,g,b});
      }
      
      for(let frame of inputFrames) {
        let {r, g, b} = frame;
        let rgba = [];
        for(let i = 0; i < frameSize*frameSize; i++) {
          rgba.push([Math.round(r[i]*255), Math.round(g[i]*255), Math.round(b[i]*255), 255])
        }
        let canvas = createCanvasFromRGBAData(rgba, 64, 64);
        canvas.style.border = "3px solid blue";
        document.body.appendChild(canvas);
      }*/
      
      while(1) {
        console.log("Starting inference...");
        let startTime = Date.now();
        let results = await model.run({"input": new ort.Tensor('float32', inputData, [1,10,3,64,64])});
        let output = results["output"]; // float32[1,10,3,64,64]
        timePer10Frames = Date.now()-startTime;
        console.log(`Inference took ${timePer10Frames}ms`);

        let pytorch = exampleData.pytorch_prediction[batchI].flat().flat().flat().flat().flat();
        let onnx = [...output.data];
        let groundTruth = exampleData.ground_truth[batchI].flat().flat().flat().flat().flat();

        console.log("Predicted:", onnx);
        
        // Display the output frames:
        let outputFrames = [];
        let outputData = [...output.data];

        if(outputData.length !== 10*3*64*64) console.error("outputData.length !== 10*3*64*64");

        for(let i = 0; i < 10; i++) {
          let s = frameSize*frameSize;
          let r = outputData.slice(3*i*s + s*0, 3*i*s + s*1);
          let g = outputData.slice(3*i*s + s*1, 3*i*s + s*2);
          let b = outputData.slice(3*i*s + s*2, 3*i*s + s*3);
          outputFrames.push({r,g,b});
        }

        for(let frame of outputFrames) {
          let {r, g, b} = frame;
          let rgba = [];
          for(let i = 0; i < frameSize*frameSize; i++) {
            rgba.push([Math.round(r[i]*255), Math.round(g[i]*255), Math.round(b[i]*255), 255])
          }
          frameQueue.unshift(rgba);
        }
        
        inputData = outputData; // feed output back into input
      }
    }
    
    let frameQueue = [];
    let timePer10Frames = 2000; //ms
    (async function() {
      while(1) {
        while(frameQueue.length === 0) await new Promise(r => setTimeout(r, 1));
        await new Promise(r => setTimeout(r, timePer10Frames/10));
        let rgba = frameQueue.pop();
        let canvas = createCanvasFromRGBAData(rgba, 64, 64);
        canvas.style.cssText = "border:3px solid green; height:256px;";
        frameCtn.innerHTML = "";
        frameCtn.appendChild(canvas);
      }
    })();
    
    
    function createCanvasFromRGBAData(data, width, height) {
      // `data` should look something like [[123,32,40,255], [3,233,42,120], ...]
      if(width*height !== data.length) throw new Error("width*height should equal data.length");
      let canvas = document.createElement("canvas");
      canvas.width = width;
      canvas.height = height;
      let ctx = canvas.getContext("2d");
      let imgData = ctx.createImageData(width, height);
      for(let i = 0; i < data.length; i++) {
        imgData.data[i*4+0] = data[i][0];
        imgData.data[i*4+1] = data[i][1];
        imgData.data[i*4+2] = data[i][2];
        imgData.data[i*4+3] = data[i][3];
      }
      ctx.putImageData(imgData, 0, 0);
      return canvas;
    }
  </script>
</body>
</html>
